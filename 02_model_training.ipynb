{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85c45c37-c98d-40e1-b3e7-b9ee62843b33",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "\n",
    "\n",
    "```python\n",
    "# --- Logistic Regression Run ---\n",
    "with mlflow.start_run(run_name=\"LogisticRegression_Baseline\"):\n",
    "    # Create the full pipeline:\n",
    "    # 1. Preprocess the data\n",
    "    # 2. Apply SMOTE to the training data *only*\n",
    "    # 3. Train the model\n",
    "    lr_pipeline = ImbPipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('smote', SMOTE(random_state=42)),\n",
    "        ('classifier', LogisticRegression(random_state=42))\n",
    "    ])\n",
    "    \n",
    "    # Train the model\n",
    "    lr_pipeline.fit(X_train, y_train)\n",
    "    \n",
    "   \n",
    "\n",
    "### **Code Cell 6: Train Model 2 (Challenger: XGBoost)**\n",
    "\n",
    "Now we train our more complex model, `XGBClassifier`. The setup is identical, which shows the power of pipelines.\n",
    "\n",
    "```python\n",
    "# --- XGBoost Run ---\n",
    "with mlflow.start_run(run_name=\"XGBoost_Challenger\"):\n",
    "    \n",
    "    # Create the full pipeline\n",
    "    xgb_pipeline = ImbPipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('smote', SMOTE(random_state=42)),\n",
    "        ('classifier', XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss'))\n",
    "    ])\n",
    "    \n",
    "    # Train the model\n",
    "    xgb_pipeline.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = xgb_pipeline.predict(X_test)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    \n",
    "    # Log parameters to MLflow\n",
    "    mlflow.log_param(\"model_type\", \"XGBClassifier\")\n",
    "    mlflow.log_param(\"smote_enabled\", \"True\")\n",
    "    \n",
    "    # Log metrics to MLflow\n",
    "    mlflow.log_metric(\"f1_score\", f1)\n",
    "    mlflow.log_metric(\"precision_score\", precision)\n",
    "    mlflow.log_metric(\"recall_score\", recall)\n",
    "    \n",
    "    # Log the model itself\n",
    "    mlflow.sklearn.log_model(xgb_pipeline, \"model\")\n",
    "    \n",
    "    print(\"\\n--- XGBoost Results ---\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "```\n",
    "\n",
    "-----\n",
    "\n",
    "### **Final Step: Check Your MLflow UI**\n",
    "\n",
    "After you run these cells, go back to your **MLflow UI browser tab** (at `http://127.0.0.1:5000`) and **hit refresh**.\n",
    "\n",
    "You should now see your \"Proactive Churn Prediction\" experiment. Click it, and you'll find two runs:\n",
    "\n",
    "  * `LogisticRegression_Baseline`\n",
    "  * `XGBoost_Challenger`\n",
    "\n",
    "You can click each one to see the parameters (like `model_type`) and metrics (like `f1_score`) that we logged. This is the \"experiment tracking\" part of the project, and it's a very impressive skill to show.\n",
    "\n",
    "We have successfully trained, compared, and logged our models\\! Phase 3 is complete."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec86d584-0ccd-4d6e-924d-5cb6046f3063",
   "metadata": {},
   "source": [
    "## **Phase 3: Model Training & Tracking**.\n",
    "\n",
    "This is the \"machine learning\" part. We'll use the clean `model_input.csv` to train and compare two models: a simple baseline (Logistic Regression) and a more powerful one (XGBoost).\n",
    "\n",
    "Most importantly, we'll use **MLflow** to track every experiment, which is a critical MLOps skill.\n",
    "\n",
    "-----\n",
    "\n",
    "### **Preparation: Install New Packages**\n",
    "\n",
    "Before starting the notebook, we need to install the packages for this phase. Go to your **terminal** (with the `(venv)` active) and run this:\n",
    "\n",
    "```bash\n",
    "pip install mlflow xgboost imbalanced-learn scikit-learn\n",
    "```\n",
    "\n",
    "Once installed, **update your `requirements.txt` file**. Open it and add these new lines so it looks like this:\n",
    "\n",
    "```\n",
    "pandas\n",
    "numpy\n",
    "scikit-learn\n",
    "jupyterlab\n",
    "mlflow\n",
    "xgboost\n",
    "imbalanced-learn\n",
    "```\n",
    "\n",
    "-----\n",
    "\n",
    "#### **Step 1: Launch MLflow UI**\n",
    "\n",
    "In your terminal, run this command. This starts the MLflow tracking server.\n",
    "\n",
    "```bash\n",
    "mlflow ui\n",
    "```\n",
    "\n",
    "This will open a new browser tab (usually at `http://127.0.0.1:5000`). Keep this tab open. It's currently empty, but our experiments will appear here.\n",
    "\n",
    "-----\n",
    "\n",
    "#### **Step 2:  Imports and Setup**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "673bd15f-8f0d-4965-8b38-b1523f920b92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported and MLflow experiment set.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>tenure_days</th>\n",
       "      <th>days_since_last_event</th>\n",
       "      <th>total_support_tickets</th>\n",
       "      <th>has_billing_issue</th>\n",
       "      <th>plan_type</th>\n",
       "      <th>billing_cycle</th>\n",
       "      <th>churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>419</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Basic</td>\n",
       "      <td>Annual</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>299</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Basic</td>\n",
       "      <td>Monthly</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>341</td>\n",
       "      <td>37</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Basic</td>\n",
       "      <td>Monthly</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>330</td>\n",
       "      <td>51</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Basic</td>\n",
       "      <td>Annual</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>443</td>\n",
       "      <td>19</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Basic</td>\n",
       "      <td>Annual</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  tenure_days  ...  billing_cycle  churn\n",
       "0        1          419  ...         Annual  False\n",
       "1        2          299  ...        Monthly  False\n",
       "2        3          341  ...        Monthly  False\n",
       "3        4          330  ...         Annual  False\n",
       "4        5          443  ...         Annual  False\n",
       "\n",
       "[5 rows x 8 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score\n",
    "from xgboost import XGBClassifier\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Load the clean data\n",
    "df_model_input = pd.read_csv(\"data/model_input.csv\")\n",
    "\n",
    "# Set the MLflow tracking URI (this points to the server we just started)\n",
    "# This links our script to the MLflow UI\n",
    "\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")\n",
    "\n",
    "# Set a name for our experiment\n",
    "mlflow.set_experiment(\"Proactive Churn Prediction\")\n",
    "\n",
    "print(\"Libraries imported and MLflow experiment set.\")\n",
    "df_model_input.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "582c141a-84fb-400d-bdd9-9e5a53d29a78",
   "metadata": {},
   "source": [
    "#### **Step 3:  Define Features (X) and Target (y)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f30fc7dd-20db-4711-9279-aedfe5f487cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features and target defined.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tenure_days</th>\n",
       "      <th>days_since_last_event</th>\n",
       "      <th>total_support_tickets</th>\n",
       "      <th>has_billing_issue</th>\n",
       "      <th>plan_type</th>\n",
       "      <th>billing_cycle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>419</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Basic</td>\n",
       "      <td>Annual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>299</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Basic</td>\n",
       "      <td>Monthly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>341</td>\n",
       "      <td>37</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Basic</td>\n",
       "      <td>Monthly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>330</td>\n",
       "      <td>51</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Basic</td>\n",
       "      <td>Annual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>443</td>\n",
       "      <td>19</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Basic</td>\n",
       "      <td>Annual</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tenure_days  days_since_last_event  ...  plan_type  billing_cycle\n",
       "0          419                      8  ...      Basic         Annual\n",
       "1          299                      2  ...      Basic        Monthly\n",
       "2          341                     37  ...      Basic        Monthly\n",
       "3          330                     51  ...      Basic         Annual\n",
       "4          443                     19  ...      Basic         Annual\n",
       "\n",
       "[5 rows x 6 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 'user_id' is an identifier, not a feature\n",
    "# 'churn' is our target\n",
    "df_model_input = df_model_input.drop('user_id', axis=1)\n",
    "\n",
    "# Define our features (X) and target (y)\n",
    "X = df_model_input.drop('churn', axis=1)\n",
    "y = df_model_input['churn']\n",
    "\n",
    "# Identify which columns are categorical and which are numerical\n",
    "categorical_features = ['plan_type', 'billing_cycle']\n",
    "numerical_features = ['tenure_days', 'days_since_last_event', 'total_support_tickets', 'has_billing_issue']\n",
    "\n",
    "print(\"Features and target defined.\")\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff40fb06-0c9f-4fee-a834-4f06ae7653f3",
   "metadata": {},
   "source": [
    "#### **Step 4:  Create the Preprocessing Pipeline**\n",
    "\n",
    "This is a crucial step. We create a `ColumnTransformer` to automatically apply scaling to numerical features and one-hot encoding to categorical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31ac0780-0090-4226-a8d1-1fe0c38b0677",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing pipeline created\n"
     ]
    }
   ],
   "source": [
    "# Create the transformer for numerical features\n",
    "\n",
    "numeric_transformer = Pipeline(\n",
    "    steps=[(\"scaler\", StandardScaler())]\n",
    ")\n",
    "\n",
    "# Create the transformer for categorical features\n",
    "\n",
    "categorical_transformer = Pipeline(\n",
    "    steps=[(\"onehot\", OneHotEncoder(handle_unknown= \"ignore\"))]\n",
    ")\n",
    "\n",
    "# Combine these transformers into a single preprocessor\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, numerical_features),\n",
    "        (\"cat\", categorical_transformer,categorical_features)\n",
    "    ])\n",
    "\n",
    "print(\"Preprocessing pipeline created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e761c9e5-13d4-48eb-a585-0c1d8c2baff0",
   "metadata": {},
   "source": [
    "#### **Step 5: Split the data**\n",
    "\n",
    "We split our data into training and testing sets. Notice `stratify=y`‚Äîthis is **essential** for imbalanced datasets to ensure both sets get the same percentage of churners.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d8b23e9-05c6-4763-9281-dbf0bba90037",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (8000, 6)\n",
      "Testing set shape: (2000, 6)\n",
      "Training set churn rate: 0.0481\n",
      "Testing set churn rate: 0.0480\n"
     ]
    }
   ],
   "source": [
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "print(f\"Training set shape: {X_train.shape}\")\n",
    "print(f\"Testing set shape: {X_test.shape}\")\n",
    "print(f\"Training set churn rate: {y_train.mean():.4f}\")\n",
    "print(f\"Testing set churn rate: {y_test.mean():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9718a126-1dbf-4f92-a86c-d866ffe9e6b2",
   "metadata": {},
   "source": [
    "#### **Step 6: Train Model 1 (Baseline: Logistic Regression)**\n",
    "\n",
    "Here is our first experiment. We use `mlflow.start_run()` to log everything. We also add `SMOTE()` to our pipeline to handle the class imbalance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "54486f4a-3cc8-4b49-a749-5d34087a784a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/18 21:36:44 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/10/18 21:37:09 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Logistic Regression Results ---\n",
      "F1 Score: 0.5073\n",
      "Precision: 0.3522\n",
      "Recall: 0.9062\n",
      "üèÉ View run LogisticRegression_Baseline at: http://127.0.0.1:5000/#/experiments/178087657089640150/runs/a071ecf6b87b42b5806c9bac24048d50\n",
      "üß™ View experiment at: http://127.0.0.1:5000/#/experiments/178087657089640150\n"
     ]
    }
   ],
   "source": [
    "# --- Logistic Regression Run ---\n",
    "with mlflow.start_run(run_name=\"LogisticRegression_Baseline\"):\n",
    "    # Create the full pipeline:\n",
    "    # 1. Preprocess the data\n",
    "    # 2. Apply SMOTE to the training data *only*\n",
    "    # 3. Train the model\n",
    "    lr_pipeline = ImbPipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('smote', SMOTE(random_state=42)),\n",
    "        ('classifier', LogisticRegression(random_state=42))\n",
    "    ])\n",
    "    \n",
    "    # Train the model\n",
    "    lr_pipeline.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = lr_pipeline.predict(X_test)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    \n",
    "    # Log parameters to MLflow\n",
    "    mlflow.log_param(\"model_type\", \"LogisticRegression\")\n",
    "    mlflow.log_param(\"smote_enabled\", \"True\")\n",
    "    \n",
    "    # Log metrics to MLflow\n",
    "    mlflow.log_metric(\"f1_score\", f1)\n",
    "    mlflow.log_metric(\"precision_score\", precision)\n",
    "    mlflow.log_metric(\"recall_score\", recall)\n",
    "    \n",
    "    # Log the model itself\n",
    "    mlflow.sklearn.log_model(lr_pipeline, \"model\")\n",
    "    \n",
    "    print(\"--- Logistic Regression Results ---\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36969b6d-7200-4718-bd94-088298dfefc8",
   "metadata": {},
   "source": [
    "### ** Step 7: Train Model 2 (Challenger: XGBoost)**\n",
    "\n",
    "Now we train our more complex model, `XGBClassifier`. The setup is identical, which shows the power of pipelines.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "78c91196-c595-44bf-aa42-cbe0924a5627",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chethan Vakiti\\proactive_churn_project\\venv\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [21:42:12] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "2025/10/18 21:42:13 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/10/18 21:42:28 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- XGBoost Results ---\n",
      "F1 Score: 0.7707\n",
      "Precision: 0.7248\n",
      "Recall: 0.8229\n",
      "üèÉ View run XGBoost_Challenger at: http://127.0.0.1:5000/#/experiments/178087657089640150/runs/671601d8c7674c188193c47eb56462e4\n",
      "üß™ View experiment at: http://127.0.0.1:5000/#/experiments/178087657089640150\n"
     ]
    }
   ],
   "source": [
    "# --- XGBoost Run ---\n",
    "with mlflow.start_run(run_name=\"XGBoost_Challenger\"):\n",
    "    \n",
    "    # Create the full pipeline\n",
    "    xgb_pipeline = ImbPipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('smote', SMOTE(random_state=42)),\n",
    "        ('classifier', XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss'))\n",
    "    ])\n",
    "    \n",
    "    # Train the model\n",
    "    xgb_pipeline.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = xgb_pipeline.predict(X_test)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    \n",
    "    # Log parameters to MLflow\n",
    "    mlflow.log_param(\"model_type\", \"XGBClassifier\")\n",
    "    mlflow.log_param(\"smote_enabled\", \"True\")\n",
    "    \n",
    "    # Log metrics to MLflow\n",
    "    mlflow.log_metric(\"f1_score\", f1)\n",
    "    mlflow.log_metric(\"precision_score\", precision)\n",
    "    mlflow.log_metric(\"recall_score\", recall)\n",
    "    \n",
    "    # Log the model itself\n",
    "    mlflow.sklearn.log_model(xgb_pipeline, \"model\")\n",
    "    \n",
    "    print(\"\\n--- XGBoost Results ---\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324569f7-c354-4427-b336-546c4ee9059f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "100370bc-229e-4753-8fc8-34a3f0348922",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "| Metric | Logistic Regression (Baseline) | XGBoost (Challenger) | Change |\n",
    "| :--- | :--- | :--- | :--- |\n",
    "| **F1 Score** | 0.5073 | **0.7707** | **+51.9%** üìà |\n",
    "| **Precision** | 0.3522 | **0.7248** | **+105.8%** üöÄ |\n",
    "| **Recall** | 0.9062 | **0.8229** | -9.1% üìâ |\n",
    "\n",
    "### Analysis\n",
    "\n",
    "This is a huge win. Here's the business translation:\n",
    "\n",
    "* Our **Recall** is still strong (82%). We are still catching the vast majority of churners.\n",
    "* Our **Precision** *more than doubled*. This means we've massively reduced the number of \"false positives.\" We are no longer wasting a huge portion of our retention budget on happy customers.\n",
    "* The **F1 Score** (the balance between them) shows that **XGBoost is the clear winner**. It provides a much more efficient and practical business solution.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d95802d-6451-4787-8c7f-5e1280b289c8",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Phase 3 Summary\n",
    "\n",
    "In this phase, **we** successfully trained and evaluated our machine learning models, moving from raw data to actionable intelligence.\n",
    "\n",
    "1.  **Environment Upgraded:** We installed the necessary ML libraries (`xgboost`, `mlflow`, `imbalanced-learn`) and set up the **MLflow UI**, a professional tool for tracking our experiments.\n",
    "2.  **Preprocessing Pipeline:** We built a `scikit-learn` pipeline to automatically **scale** our numerical data and **one-hot encode** our categorical data, ensuring our model receives clean, standardized input.\n",
    "3.  **Handling Imbalance:** We integrated **SMOTE** (Synthetic Minority Over-sampling Technique) into our pipeline. This fixed our class imbalance problem by creating synthetic \"churner\" examples for the model to learn from.\n",
    "4.  **Model Experimentation:** We trained and logged two different models:\n",
    "    * **Baseline (Logistic Regression):** This gave us a starting point, showing high recall but very low precision.\n",
    "    * **Challenger (XGBoost):** This model was a clear winner, dramatically improving our precision while maintaining high recall, resulting in a much higher F1-score.\n",
    "5.  **Tracking & Comparison:** We used **MLflow** to log every parameter and metric for both runs. This allows us to compare our models side-by-side and definitively prove *why* XGBoost is the superior model for this business problem.\n",
    "\n",
    "We now have a high-performing, tracked, and saved champion model ready to be deployed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a2ce24-66e2-48e8-a5c8-5a8ad3c2e3ff",
   "metadata": {},
   "source": [
    "\n",
    "### Phase 4 Summary\n",
    "\n",
    "In this phase, **we** successfully deployed our champion model as a live, interactive, and optimized web application.\n",
    "\n",
    "1.  **Microservice API (The \"Brain\"):** We built a **FastAPI** microservice. This API loads our best XGBoost model directly from the **MLflow** server when it starts.\n",
    "2.  **Dashboard UI (The \"Face\"):** We built a user-friendly **Streamlit** dashboard. This app provides a simple interface for a non-technical manager to get the at-risk user list.\n",
    "3.  **Full-Stack Connection:** We connected the two components. The Streamlit app sends a request to the FastAPI API, which returns the prioritized list for display.\n",
    "4.  **Production-Level Optimization:** When we saw the app was slow, we **refactored our API** to pre-calculate all 10,000 predictions *once* at startup. This made the dashboard **instantaneous**‚Äîa critical optimization for a real-world product.\n",
    "\n",
    "You've completed the hardest part. The final step is to package it all up so anyone, anywhere, can run your project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff448b3-e0a5-441e-b6fa-a264d6253ff8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
